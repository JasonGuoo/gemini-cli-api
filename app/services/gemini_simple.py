#!/usr/bin/env python3
"""
ç®€åŒ–çš„Gemini CLIæœåŠ¡ - ä½¿ç”¨ -p å‚æ•°è¿›è¡Œéäº¤äº’å¼è°ƒç”¨
æ— éœ€å¤æ‚çš„è¿›ç¨‹æ± ã€PTYé€šä¿¡æˆ–ANSIç å¤„ç†
"""

import asyncio
import json
import os
import re
from typing import AsyncGenerator, Optional


class SimplifiedGeminiCLI:
    """
    ç®€åŒ–çš„Gemini CLIåŒ…è£…å™¨
    
    ä½¿ç”¨ -p å‚æ•°ç›´æ¥è°ƒç”¨ï¼Œé¿å…äº¤äº’å¼ç•Œé¢çš„å¤æ‚æ€§
    ä¼˜åŠ¿ï¼š
    - æ— éœ€PTYé€šä¿¡
    - æ— éœ€ANSIç å¤„ç†
    - æ— éœ€å¤æ‚çš„æ¨¡å¼åŒ¹é…
    - è¾“å‡ºç›´æ¥å¯ç”¨
    - æ›´ç¨³å®šã€æ›´ç®€å•
    """
    
    def __init__(self, cli_path: str = "/usr/local/bin/gemini"):
        self.cli_path = cli_path
    
    async def execute_prompt(
        self, 
        prompt: str, 
        model: str = "gemini-2.5-pro",
        timeout: int = 60
    ) -> str:
        """
        æ‰§è¡Œå•ä¸ªæç¤ºå¹¶è¿”å›å®Œæ•´å“åº”
        
        Args:
            prompt: ç”¨æˆ·æç¤º
            model: æ¨¡å‹åç§°
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            å®Œæ•´çš„å“åº”æ–‡æœ¬
        """
        cmd = [
            self.cli_path,
            "-m", model,
            "-p", prompt
        ]
        
        try:
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                env=os.environ.copy()
            )
            
            stdout, stderr = await asyncio.wait_for(
                process.communicate(), 
                timeout=timeout
            )
            
            if process.returncode != 0:
                error_msg = stderr.decode('utf-8', errors='ignore').strip()
                raise RuntimeError(f"Gemini CLI failed with code {process.returncode}: {error_msg}")
            
            response = stdout.decode('utf-8', errors='ignore').strip()
            return response
            
        except asyncio.TimeoutError:
            raise TimeoutError(f"Gemini CLI command timed out after {timeout} seconds")
        except Exception as e:
            raise RuntimeError(f"Failed to execute Gemini CLI: {e}")
    
    async def execute_prompt_stream(
        self, 
        prompt: str, 
        model: str = "gemini-2.5-pro",
        timeout: int = 60
    ) -> AsyncGenerator[str, None]:
        """
        æ‰§è¡Œæç¤ºå¹¶æµå¼è¿”å›å“åº”
        
        Args:
            prompt: ç”¨æˆ·æç¤º
            model: æ¨¡å‹åç§°
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Yields:
            å“åº”æ–‡æœ¬çš„ç‰‡æ®µ
        """
        cmd = [
            self.cli_path,
            "-m", model,
            "-p", prompt
        ]
        
        try:
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                env=os.environ.copy()
            )
            
            # è¯»å–stdoutæµ
            buffer = ""
            start_time = asyncio.get_event_loop().time()
            
            while True:
                current_time = asyncio.get_event_loop().time()
                if current_time - start_time > timeout:
                    process.kill()
                    raise TimeoutError(f"Gemini CLI command timed out after {timeout} seconds")
                
                try:
                    # éé˜»å¡è¯»å–
                    data = await asyncio.wait_for(
                        process.stdout.read(1024), 
                        timeout=0.1
                    )
                    
                    if not data:
                        # è¿›ç¨‹ç»“æŸ
                        break
                    
                    chunk = data.decode('utf-8', errors='ignore')
                    buffer += chunk
                    
                    # æŒ‰è¡Œåˆ†å‰²å¹¶yield
                    lines = buffer.split('\n')
                    buffer = lines[-1]  # ä¿ç•™æœ€åä¸€è¡Œï¼ˆå¯èƒ½ä¸å®Œæ•´ï¼‰
                    
                    for line in lines[:-1]:
                        if line.strip():
                            yield line.strip()
                    
                except asyncio.TimeoutError:
                    # æ²¡æœ‰æ–°æ•°æ®ï¼Œæ£€æŸ¥è¿›ç¨‹çŠ¶æ€
                    if process.returncode is not None:
                        break
                    continue
            
            # å¤„ç†å‰©ä½™çš„buffer
            if buffer.strip():
                yield buffer.strip()
            
            # ç­‰å¾…è¿›ç¨‹å®Œæˆå¹¶æ£€æŸ¥é”™è¯¯
            await process.wait()
            
            if process.returncode != 0:
                stderr_data = await process.stderr.read()
                error_msg = stderr_data.decode('utf-8', errors='ignore').strip()
                raise RuntimeError(f"Gemini CLI failed with code {process.returncode}: {error_msg}")
                
        except asyncio.TimeoutError:
            if process:
                process.kill()
            raise TimeoutError(f"Gemini CLI command timed out after {timeout} seconds")
        except Exception as e:
            if process:
                process.kill()
            raise RuntimeError(f"Failed to execute Gemini CLI: {e}")
    
    def estimate_tokens(self, text: str) -> int:
        """
        ä¼°ç®—æ–‡æœ¬çš„tokenæ•°é‡ï¼ˆç®€å•å®ç°ï¼‰
        """
        # ç®€å•çš„tokenä¼°ç®—ï¼šå¤§çº¦4ä¸ªå­—ç¬¦ = 1ä¸ªtoken
        return len(text) // 4
    
    async def get_model_info(self) -> dict:
        """
        è·å–æ¨¡å‹ä¿¡æ¯ï¼ˆå¦‚æœCLIæ”¯æŒï¼‰
        """
        try:
            cmd = [self.cli_path, "--help"]
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            # ä»å¸®åŠ©ä¿¡æ¯ä¸­æå–é»˜è®¤æ¨¡å‹
            help_text = stdout.decode('utf-8', errors='ignore')
            model_match = re.search(r'default: "(.*?)"', help_text)
            default_model = model_match.group(1) if model_match else "gemini-2.5-pro"
            
            return {
                "default_model": default_model,
                "cli_path": self.cli_path,
                "available": True
            }
            
        except Exception as e:
            return {
                "default_model": "gemini-2.5-pro",
                "cli_path": self.cli_path,
                "available": False,
                "error": str(e)
            }


# ä½¿ç”¨ç¤ºä¾‹
async def demo():
    """æ¼”ç¤ºç®€åŒ–ç‰ˆæœ¬çš„ä½¿ç”¨"""
    
    cli = SimplifiedGeminiCLI()
    
    print("ğŸ§ª æµ‹è¯•ç®€åŒ–ç‰ˆGemini CLI")
    print("=" * 50)
    
    # æµ‹è¯•è¿æ¥
    print("ğŸ”— æµ‹è¯•è¿æ¥...")
    if await cli.test_connection():
        print("âœ… è¿æ¥æˆåŠŸï¼")
    else:
        print("âŒ è¿æ¥å¤±è´¥")
        return
    
    # æµ‹è¯•ç®€å•æç¤º
    print("\nğŸ“ æµ‹è¯•ç®€å•æ•°å­¦é—®é¢˜...")
    response = await cli.execute_prompt("What is 5 + 3?")
    print(f"ğŸ¤– å“åº”: '{response}'")
    
    # æµ‹è¯•å¤æ‚æç¤º  
    print("\nğŸ“ æµ‹è¯•å¤æ‚æç¤º...")
    response = await cli.execute_prompt("Explain quantum computing in one sentence.")
    print(f"ğŸ¤– å“åº”: '{response}'")
    
    # æµ‹è¯•æµå¼è¾“å‡º
    print("\nğŸŒŠ æµ‹è¯•æµå¼è¾“å‡º...")
    print("ğŸ¤– æµå¼å“åº”:")
    async for chunk in cli.execute_prompt_stream("Write a haiku about programming."):
        print(f"   ğŸ“¤ {chunk}", end='', flush=True)
    print("\n")

if __name__ == "__main__":
    asyncio.run(demo()) 